LEA_foods = read_csv("/Users/abhilashakumar/Documents/active projects/fluency projects/fluency_switch/fluency-switch-experiment/forager_test/data/fluency_lists/reed_foods_RTs.csv") %>%
filter(subject > 5000) %>% select(domain, subject, participant_designated_switch, response_number)
LEA_occupations = read_csv("/Users/abhilashakumar/Documents/active projects/fluency projects/fluency_switch/fluency-switch-experiment/forager_test/data/fluency_lists/reed_occupations_RTs.csv") %>%
filter(subject > 5000) %>% select(domain, subject, participant_designated_switch, response_number)
#LEA_data = rbind(LEA_animals, LEA_foods, LEA_occupations)
LEA_data = rbind(LEA_foods, LEA_occupations)
behavioral_designations = trials_agg %>% mutate(subject = as.numeric(subject)) %>% filter(subject > 5000) %>%
mutate(norms_associative = ifelse(is.na(norms_associative), 0, norms_associative),
norms_categorical = ifelse(is.na(norms_categorical), 0, norms_categorical))%>%
left_join(LEA_data)
my_data <- behavioral_designations %>% ungroup() %>% select(subject, domain, participant_designated_switch, simdrop:exp) %>%
ungroup() %>%
filter(!is.na(simdrop))# grouping at the level of subject (list)
# Get the list of predictor variables (columns) from the dataframe
predictor_columns <- setdiff(names(my_data), c("participant_designated_switch", "subject", "domain"))
# Clean predictor column names in the dataframe
cleaned_data <- my_data %>%
rename_with(clean_column_names, .cols = predictor_columns)
# Get the list of predictor variables (columns) from the dataframe
predictor_columns <- setdiff(names(cleaned_data), c("participant_designated_switch", "subject", "domain"))
model_results <- cleaned_data %>%
group_by(domain) %>%
summarise(model = map(setNames(predictor_columns, predictor_columns),
~ fit_model(df = cur_data(), column = .x, type = "glmer", dv = "participant_designated_switch",
var_cutoff = .049)))%>%
unnest(cols = c(model)) %>%
mutate(across(Log_Likelihood:N_Observations, ~ as.vector(.)))
model_results %>%
group_by(domain) %>%
slice_max(R_squared)
subject_model_results <- cleaned_data %>%
group_by(domain, subject) %>%
summarise(model = map(setNames(predictor_columns, predictor_columns),
~ {
fit_model(df = cur_data(), column = .x, type = "subject", dv = "participant_designated_switch",
var_cutoff = .049)
})) %>%
unnest(cols = c(model)) %>%
mutate(across(Log_Likelihood:N_Observations, ~ as.vector(.)))
top_subjects = subject_model_results %>%
group_by(subject, domain) %>%
slice_max(R_squared)
View(top_subjects)
top_methods = top_subjects%>%
group_by(Predictor) %>%
count()
View(top_methods)
all_domains = rbind(animals, foods, occupations)
trials_agg = nonfirst_trials %>%
mutate(current_pair = str_replace(current_pair, "hello", cluster)) %>%
group_by(subject, domain, response_number, current_pair) %>%
summarise(mean_response = mean(response),
num_responses = n())
trials_agg = trials_agg %>%
left_join(all_domains) %>%
filter(!is.na(cluster))
plot_agg = trials_agg %>%
group_by(domain, current_pair) %>%
summarize(score = mean(mean_response),
num_responses = n()) %>%
mutate(current_pair = str_replace(current_pair, ", ", "-"))
View(plot_agg)
View(plot_agg)
View(trials_agg)
plot_agg = nonfirst_trials %>%
mutate(current_pair = str_replace(current_pair, "hello", cluster)) %>%
group_by(subject, domain, response_number, current_pair) %>%
summarise(mean_response = mean(response),
num_responses = n()) %>%
mutate(current_pair = str_replace(current_pair, ", ", "-"))
plot_agg = nonfirst_trials %>%
mutate(current_pair = str_replace(current_pair, "hello", cluster)) %>%
group_by(domain, current_pair) %>%
summarise(mean_response = mean(response),
num_responses = n()) %>%
mutate(current_pair = str_replace(current_pair, ", ", "-"))
View(plot_agg)
plot_agg %>%
ggplot(aes(x = domain, y = score, fill = domain)) +
geom_violin() +
geom_boxplot(width = 0.2, color = "black", alpha = 0) +
geom_hline(yintercept = high_score_threshold, linetype = "dashed", color = "green") +
geom_hline(yintercept = low_score_threshold, linetype = "dashed", color = "red") +
geom_text(data = plot_agg %>% filter(current_pair %in% sample_words),
aes(label = current_pair),
size = 4, hjust = 0.8, vjust = 0.5, position = position_jitter(height = 0.1))+
labs(title = "Distribution of Mean Scores for Different Word Pairs",
x = "",
y = "mean score") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.5)),
legend.position = "none")+
guides(fill = FALSE)  # Hide legend for color scale
high_score_threshold = 0.9
low_score_threshold = 0.1
sample_words = plot_agg %>%
group_by(domain) %>%
sample_n(5, replace = FALSE) %>% pull(current_pair)
plot_agg %>%
ggplot(aes(x = domain, y = score, fill = domain)) +
geom_violin() +
geom_boxplot(width = 0.2, color = "black", alpha = 0) +
geom_hline(yintercept = high_score_threshold, linetype = "dashed", color = "green") +
geom_hline(yintercept = low_score_threshold, linetype = "dashed", color = "red") +
geom_text(data = plot_agg %>% filter(current_pair %in% sample_words),
aes(label = current_pair),
size = 4, hjust = 0.8, vjust = 0.5, position = position_jitter(height = 0.1))+
labs(title = "Distribution of Mean Scores for Different Word Pairs",
x = "",
y = "mean score") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.5)),
legend.position = "none")+
guides(fill = FALSE)  # Hide legend for color scale
plot_agg %>%
ggplot(aes(x = domain, y = mean_response, fill = domain)) +
geom_violin() +
geom_boxplot(width = 0.2, color = "black", alpha = 0) +
geom_hline(yintercept = high_score_threshold, linetype = "dashed", color = "green") +
geom_hline(yintercept = low_score_threshold, linetype = "dashed", color = "red") +
geom_text(data = plot_agg %>% filter(current_pair %in% sample_words),
aes(label = current_pair),
size = 4, hjust = 0.8, vjust = 0.5, position = position_jitter(height = 0.1))+
labs(title = "Distribution of Mean Scores for Different Word Pairs",
x = "",
y = "mean score") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.5)),
legend.position = "none")+
guides(fill = FALSE)  # Hide legend for color scale
hist(plot_agg$mean_response)
plot_agg %>%
ggplot(aes(x = mean_response, fill = domain)) +
geom_histogram()
plot_agg %>%
ggplot(aes(x = mean_response, fill = domain)) +
geom_density()
plot_agg %>%
ggplot(aes(x = mean_response, fill = domain)) +
geom_density(alpha = 0.4)
plot_agg %>%
ggplot(aes(x = mean_response, fill = domain)) +
geom_density(alpha = 0.4)+
# geom_violin() +
# geom_boxplot(width = 0.2, color = "black", alpha = 0) +
# geom_hline(yintercept = high_score_threshold, linetype = "dashed", color = "green") +
# geom_hline(yintercept = low_score_threshold, linetype = "dashed", color = "red") +
# geom_text(data = plot_agg %>% filter(current_pair %in% sample_words),
#           aes(label = current_pair),
#           size = 4, hjust = 0.8, vjust = 0.5, position = position_jitter(height = 0.1))+
labs(title = "Distribution of Mean Scores for Different Word Pairs",
x = "",
y = "mean score") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.5)),
legend.position = "none")+
guides(fill = FALSE)  # Hide legend for color scale
plot_agg %>%
ggplot(aes(x = mean_response, fill = domain)) +
geom_density(alpha = 0.4)+
# geom_violin() +
# geom_boxplot(width = 0.2, color = "black", alpha = 0) +
# geom_hline(yintercept = high_score_threshold, linetype = "dashed", color = "green") +
# geom_hline(yintercept = low_score_threshold, linetype = "dashed", color = "red") +
geom_text(data = plot_agg %>% filter(current_pair %in% sample_words),
aes(label = current_pair),
size = 4, hjust = 0.8, vjust = 0.5, position = position_jitter(height = 0.1))+
labs(title = "Distribution of Mean Scores for Different Word Pairs",
x = "",
y = "mean score") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.5)),
legend.position = "none")+
guides(fill = FALSE)  # Hide legend for color scale
plot_agg %>%
ggplot(aes(x = mean_response, fill = domain)) +
geom_density(alpha = 0.4)+
# geom_violin() +
# geom_boxplot(width = 0.2, color = "black", alpha = 0) +
# geom_hline(yintercept = high_score_threshold, linetype = "dashed", color = "green") +
# geom_hline(yintercept = low_score_threshold, linetype = "dashed", color = "red") +
# geom_text(data = plot_agg %>% filter(current_pair %in% sample_words),
#           aes(label = current_pair),
#           size = 4, hjust = 0.8, vjust = 0.5, position = position_jitter(height = 0.1))+
labs(title = "Distribution of Mean Scores for Different Word Pairs",
x = "",
y = "mean score") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.5)),
legend.position = "none")+
guides(fill = FALSE)  # Hide legend for color scale
plot_agg %>%
ggplot(aes(x = mean_response, fill = domain)) +
geom_density(alpha = 0.4)+
# geom_violin() +
# geom_boxplot(width = 0.2, color = "black", alpha = 0) +
# geom_hline(yintercept = high_score_threshold, linetype = "dashed", color = "green") +
# geom_hline(yintercept = low_score_threshold, linetype = "dashed", color = "red") +
# geom_text(data = plot_agg %>% filter(current_pair %in% sample_words),
#           aes(label = current_pair),
#           size = 4, hjust = 0.8, vjust = 0.5, position = position_jitter(height = 0.1))+
labs(title = "Distribution of Mean Scores for Different Word Pairs",
x = "",
y = "mean score") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.5)))
plot_agg %>%
ggplot(aes(x = mean_response, fill = domain)) +
geom_density(alpha = 0.4)+
# geom_violin() +
# geom_boxplot(width = 0.2, color = "black", alpha = 0) +
# geom_hline(yintercept = high_score_threshold, linetype = "dashed", color = "green") +
# geom_hline(yintercept = low_score_threshold, linetype = "dashed", color = "red") +
# geom_text(data = plot_agg %>% filter(current_pair %in% sample_words),
#           aes(label = current_pair),
#           size = 4, hjust = 0.8, vjust = 0.5, position = position_jitter(height = 0.1))+
labs(title = "Distribution of Mean Scores for Different Word Pairs",
x = "",
y = "mean score") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.2)))
my_data <- trials_agg %>% ungroup() %>% select(subject, domain, mean_response, simdrop:exp) %>% ungroup() %>%
mutate(norms_associative = ifelse(is.na(norms_associative), 0, norms_associative),
norms_categorical = ifelse(is.na(norms_categorical), 0, norms_categorical))%>%
filter(!is.na(simdrop))# grouping at the level of subject (list)
# Get the list of predictor variables (columns) from the dataframe
predictor_columns <- setdiff(names(my_data), c("mean_response", "subject", "domain"))
# Clean predictor column names in the dataframe
cleaned_data <- my_data %>%
rename_with(clean_column_names, .cols = predictor_columns)
# Get the list of predictor variables (columns) from the dataframe
predictor_columns <- setdiff(names(cleaned_data), c("mean_response", "subject", "domain"))
model_results <- cleaned_data %>%
group_by(domain) %>%
summarise(model = map(setNames(predictor_columns, predictor_columns),
~ fit_model(df = cur_data(), column = .x, type = "lmer", dv = "mean_response",
var_cutoff = .049)))%>%
unnest(cols = c(model)) %>%
mutate(across(Log_Likelihood:N_Observations, ~ as.vector(.)))
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(stringdist)
library(lme4)
library(lmerTest)
library(broom.mixed)
data = read_csv("../data/fluency-switch.csv")
#View(data %>% filter(ID == 11750 & type_of_trial == "attention" & !is.na(response)) %>% select(response, current_pair, attention))
trials = data %>% filter(type_of_trial == "comparison") %>% mutate(cluster = tolower(cluster))
## filter out IDs with incomplete data
insufficient_trials = trials %>%
group_by(ID, domain, subject) %>%
count() %>%
group_by(ID, domain) %>%
count()%>%
filter(n != 6)
trials = trials %>%
filter(!(ID %in% insufficient_trials$ID))
## filter based on attention checks
attention = data %>% filter(type_of_trial == "attention" & !is.na(response)) %>%
separate(current_pair, into = c("prev", "current"), sep = ",") %>%
mutate(attn_corr = ifelse((stringdist(tolower(response), prev, method = "lv") < 2 ) |
(stringdist(tolower(response), current, method = "lv") < 2 ), 1, 0))
ID_attn = attention %>%
group_by(ID) %>%
summarise(n_correct = sum(attn_corr))
insufficient_attentions = ID_attn %>%
filter(n_correct < 15 & n_correct >0)
trials = trials %>%
filter(!(ID %in% insufficient_attentions$ID)) %>%
mutate(response = as.numeric(response))
## FINAL SAMPLE ##
length(trials %>% pull(ID) %>% unique())
nonfirst_trials = trials %>%
filter(response!= 2)
length(unique(trials$ID))
data = read_csv("../data/fluency-switch.csv")
#View(data %>% filter(ID == 11750 & type_of_trial == "attention" & !is.na(response)) %>% select(response, current_pair, attention))
trials = data %>% filter(type_of_trial == "comparison") %>% mutate(cluster = tolower(cluster))
length(unique(trials$ID))
## filter out IDs with incomplete data
insufficient_trials = trials %>%
group_by(ID, domain, subject) %>%
count() %>%
group_by(ID, domain) %>%
count()%>%
filter(n != 6)
trials = trials %>%
filter(!(ID %in% insufficient_trials$ID))
## filter based on attention checks
attention = data %>% filter(type_of_trial == "attention" & !is.na(response)) %>%
separate(current_pair, into = c("prev", "current"), sep = ",") %>%
mutate(attn_corr = ifelse((stringdist(tolower(response), prev, method = "lv") < 2 ) |
(stringdist(tolower(response), current, method = "lv") < 2 ), 1, 0))
ID_attn = attention %>%
group_by(ID) %>%
summarise(n_correct = sum(attn_corr))
insufficient_attentions = ID_attn %>%
filter(n_correct < 15 & n_correct >0)
trials = trials %>%
filter(!(ID %in% insufficient_attentions$ID)) %>%
mutate(response = as.numeric(response))
## FINAL SAMPLE ##
length(trials %>% pull(ID) %>% unique())
nonfirst_trials = trials %>%
filter(response!= 2)
foods = read_csv("../forager_test/output/foods_words_forager_switchresults.csv") %>%
rowwise() %>% group_by(Subject, Switch_Method) %>% mutate(response_number = row_number())%>%
select(-c(Semantic_Similarity, Phonological_Similarity, Frequency_Value)) %>%
pivot_wider(names_from = Switch_Method, values_from = Switch_Value) %>%
rename(subject = Subject, cluster = Fluency_Item) %>%
mutate(subject = as.character(subject))%>%
mutate(domain = "foods")
animals = read_csv("../forager_test/output/animals_words_forager_switchresults.csv") %>%
rowwise() %>% group_by(Subject, Switch_Method) %>% mutate(response_number = row_number())%>%
#select(-c(Semantic_Similarity, Phonological_Similarity, Frequency_Value)) %>%
select(-c(Semantic_Similarity, Frequency_Value)) %>%
pivot_wider(names_from = Switch_Method, values_from = Switch_Value) %>%
rename(subject = Subject, cluster = Fluency_Item) %>%
mutate(subject = as.character(subject))%>%
mutate(domain = "animals")
occupations = read_csv("../forager_test/output/occupations_words_forager_switchresults.csv") %>%
rowwise() %>% group_by(Subject, Switch_Method) %>% mutate(response_number = row_number())%>%
select(-c(Semantic_Similarity, Phonological_Similarity, Frequency_Value)) %>%
pivot_wider(names_from = Switch_Method, values_from = Switch_Value) %>%
rename(subject = Subject, cluster = Fluency_Item) %>%
mutate(subject = as.character(subject)) %>%
mutate(domain = "occupations")
all_domains = rbind(animals, foods, occupations)
trials_agg = nonfirst_trials %>%
mutate(current_pair = str_replace(current_pair, "hello", cluster)) %>%
group_by(subject, domain, response_number, current_pair) %>%
summarise(mean_response = mean(response),
num_responses = n())
trials_agg = trials_agg %>%
left_join(all_domains) %>%
filter(!is.na(cluster))
# Function to clean column names by replacing special characters with underscores
clean_column_names <- function(column_names) {
str_replace_all(column_names, "[^[:alnum:] ]", "_")
}
# Define a function to fit the glmer model for each cleaned predictor column
fit_model <- function(df, column, type, dv, var_cutoff) {
# calculate variance of the column
var_col = var(df[column])
if (var_col > var_cutoff) {
if(type == "glmer"){
model_formula <- as.formula(paste(dv, " ~ ", column, "+ (1 | subject)"))
model <- glmer(model_formula, data = df, family = binomial)
estimate <- fixef(model)[column]
}
else if(type == "lmer") {
model_formula <- as.formula(paste(dv, " ~ ", column, "+ (1 | subject)"))
model <- lmer(model_formula, data = df)
estimate <- fixef(model)[column]
}
else {
## subject-level model
model_formula <- as.formula(paste(dv, " ~ ", column))
model <- lm(model_formula, data = df)
estimate <- coef(model)[column]
}
aic <- AIC(model)
bic <- BIC(model)
r_squared <- MuMIn::r.squaredGLMM(model)[1]
log_likelihood <- as.numeric(logLik(model))
n_obs <- nobs(model)
tibble(
Predictor = column,
Fixed_Effect = estimate,
AIC = aic,
BIC = bic,
R_squared = r_squared,
Log_Likelihood = log_likelihood,
N_Observations = n_obs
)
}
else{
NULL
}
}
my_data <- trials_agg %>% ungroup() %>% select(subject, domain, mean_response, simdrop:exp) %>% ungroup() %>%
mutate(norms_associative = ifelse(is.na(norms_associative), 0, norms_associative),
norms_categorical = ifelse(is.na(norms_categorical), 0, norms_categorical))%>%
filter(!is.na(simdrop))# grouping at the level of subject (list)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(stringdist)
library(lme4)
library(lmerTest)
library(broom.mixed)
setwd(here::here())
library(boot)
getwd()
data = read_csv("data/fluency-switch.csv")
sona_IDs= data %>% filter(!is.na(sona_id)) %>% select(ID) %>%distinct() %>% pull(ID)
data = read_csv("data/fluency-switch.csv")
sona_IDs= data %>% filter(!is.na(sona_id)) %>% select(ID) %>%distinct() %>% pull(ID)
data = data %>% mutate(population = ifelse(ID %in% sona_IDs, "sona", "prolific"))
prolific_IDs = data %>% filter(population == "prolific") %>% select(ID) %>% distinct() %>% pull(ID)
data_prolific_duplicates <- data %>%
filter(type_of_trial == "prolific_id") %>%
select(ID, response, recorded_at) %>% distinct() %>%
separate(response, into = c("id", "prolific_id"), sep = ":") %>%
mutate(prolific_id = gsub("[\\\\{}\"]", "", prolific_id)) %>%
mutate(prolific_id = str_replace(prolific_id, "@.*", "")) %>%
group_by(prolific_id) %>%
mutate(min_recorded_at = min(recorded_at)) %>%
ungroup() %>%
filter(recorded_at != min_recorded_at) %>%
select(ID) %>%
distinct() %>% pull(ID)
final_prolific_IDs = prolific_IDs[!prolific_IDs %in% data_prolific_duplicates]
data = data %>%
filter(ID %in% c(sona_IDs, final_prolific_IDs))
length(unique(data$ID))
trials = data %>% filter(type_of_trial == "comparison") %>% mutate(cluster = tolower(cluster))
length(unique(trials$ID))
## filter out IDs with incomplete data
insufficient_trials = trials %>%
group_by(ID, domain, subject) %>%
count() %>%
group_by(ID, domain) %>%
count()%>%
filter(n != 6)
trials = trials %>%
filter(!(ID %in% insufficient_trials$ID))
## filter based on attention checks
attention = data %>% filter(type_of_trial == "attention" & !is.na(response)) %>%
separate(current_pair, into = c("prev", "current"), sep = ",") %>%
mutate(attn_corr = ifelse((stringdist(tolower(response), prev, method = "lv") < 2 ) |
(stringdist(tolower(response), current, method = "lv") < 2 ), 1, 0))
ID_attn = attention %>%
group_by(ID) %>%
summarise(n_correct = sum(attn_corr))
insufficient_attentions = ID_attn %>%
filter(n_correct < 15 & n_correct >0)
trials = trials %>%
filter(!(ID %in% insufficient_attentions$ID)) %>%
mutate(response = as.numeric(response))
## FINAL SAMPLE ##
length(trials %>% pull(ID) %>% unique())
actual_sample_IDs = trials %>% pull(ID) %>% unique()
nonfirst_trials = trials %>%
filter(response!= 2)
strategies = data %>%
filter(ID %in% trials$ID) %>%
filter(type_of_trial == "demo"  & str_detect(response, '^\\{"Q0":"')) %>%
filter(row_number() %% 2 != 0)%>%
mutate(response = str_extract(response, '(?<=Q0":").*?(?=")')) %>%
select(ID,response)
View(strategies)
strategies = data %>%
#filter(ID %in% trials$ID) %>%
filter(type_of_trial == "demo"  & str_detect(response, '^\\{"Q0":"')) %>%
filter(row_number() %% 2 != 0)%>%
mutate(response = str_extract(response, '(?<=Q0":").*?(?=")')) %>%
select(ID,response)
write.csv(strategies, file = "ID_strategies.csv", row.names = FALSE)
x = read_csv("data/complete_model_results.csv")
x %>% filter(is.na(Negative_Log_Likelihood_Optimized))
View(x %>% filter(is.na(Negative_Log_Likelihood_Optimized)))
View(x %>% filter(is.na(Negative_Log_Likelihood_Optimized)) %>% select(Dimension, Alpha, Subject, Model, Negative_Log_Likelihood_Optimized))
