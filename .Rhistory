mutate(response = as.numeric(response))
length(trials %>% pull(ID) %>% unique())
actual_sample_IDs = trials %>% pull(ID) %>% unique()
nonfirst_trials = trials %>%
filter(response!= 2)
demo_data = data %>% filter(type_of_trial == "demo") %>%
filter(ID %in% actual_sample_IDs)
age_data = demo_data[grep('^\\{"Age', demo_data$response), ] %>%
separate(response, into = c("Age", "Gender", "Education"), sep = ",") %>%
mutate(
Age = gsub("[^0-9]+", "", Age),          # Remove non-numeric characters from Age
Gender = tolower(gsub('.*:"(.*)"', '\\1', Gender)),  # Extract the value between quotes in Gender
Education = gsub("[^0-9]+", "", Education) # Remove non-numeric characters from Education
)%>%
mutate(
Age = as.numeric(na_if(Age, "")),       # Replace empty cells in Age with NA
Gender = na_if(Gender, ""), # Replace empty cells in Gender with NA
Education = as.numeric(na_if(Education, "")) # Replace empty cells in Education with NA
) %>%
mutate(Education = ifelse(Education  == 1415, 14.5, Education))%>%
mutate(Gender = ifelse(Gender %in% c("he/him", "male", "make", "make ", "man", "m"), "men",
ifelse(Gender %in% c("female", "female ", "women", "woman"), "women",
ifelse(Gender %in% c("transgender male", "transgender"), "transgender", Gender))))
## AGE ##
age_data %>% summarize(m = mean(Age, na.rm = TRUE), sd = sd(Age, na.rm = TRUE))
## GENDER ##
age_data %>% group_by(Gender) %>%
summarize(count = n()) %>%
mutate(percent = count / sum(count) * 100)
## EDUCATION ##
age_data %>% summarize(m = mean(Education, na.rm = TRUE), sd = sd(Education, na.rm = TRUE))
## RACE ##
race_data = demo_data[grep('^\\{"Race', demo_data$response), ]%>%
filter(grepl('^\\{"Race', response)) %>%
mutate(
Race = gsub('.*\\["(.*?)\\"]}', '\\1', response)
) %>%
select(-response) %>%
select(ID, Race) %>%
mutate(RaceCat = ifelse(Race %in% c("White/Caucasian"), "White",
ifelse(Race %in% c("Black/African American"), "Black",
ifelse(Race %in% c("Asian"), "Asian",
ifelse(Race %in% c("American Indian/Alaskan Native"),
"American Indian/Alaskan Native",
"More/Other")))))
race_data %>%
group_by(RaceCat) %>%
summarize(count = n()) %>%
mutate(percent = count / sum(count) * 100)
trials_agg = nonfirst_trials %>%
mutate(current_pair = str_replace(current_pair, "hello", cluster)) %>%
group_by(subject, domain, response_number, current_pair) %>%
summarise(mean_response = mean(response),
num_responses = n())
trials_agg = trials_agg %>%
left_join(all_domains)# %>%
trials_agg = trials_agg %>%
left_join(all_domains) %>%
filter(!is.na(cluster))
trials_agg = nonfirst_trials %>%
mutate(current_pair = str_replace(current_pair, "hello", cluster)) %>%
group_by(subject, domain, response_number, current_pair) %>%
summarise(mean_response = mean(response),
num_responses = n())
View(trials_agg)
trials_agg = trials_agg %>%
left_join(all_domains) %>%
filter(!is.na(cluster))
plot_agg = nonfirst_trials %>%
mutate(current_pair = str_replace(current_pair, "hello", cluster)) %>%
group_by(domain, current_pair) %>%
summarise(mean_response = mean(response),
num_responses = n()) %>%
mutate(current_pair = str_replace(current_pair, ", ", "-"))
plot_agg %>%
ggplot(aes(x = mean_response, fill = domain)) +
geom_density(alpha = 0.4)+
labs(title = "Distribution of Mean Scores for Different Word Pairs",
x = "",
y = "mean score") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.2)))
food_lexical = read_csv("forager_test/output/foods_forager/lexical_results.csv") %>% mutate(domain = "foods")
animal_lexical = read_csv("forager_test/output/animals_forager/lexical_results.csv")%>% mutate(domain = "animals")
occupation_lexical = read_csv("forager_test/output/occupations_forager/lexical_results.csv")%>% mutate(domain = "occupations")
all_lexical = rbind(food_lexical, animal_lexical, occupation_lexical) %>%
mutate(prev = lag(Fluency_Item))%>%
mutate(current_pair = paste(prev,Fluency_Item, sep = ", ")) %>%
mutate(prev_freq = lag(Frequency_Value)) %>%
rowwise()%>%
mutate(avg_freq = sum(Frequency_Value, prev_freq)/2)
plot_agg = nonfirst_trials %>%
mutate(current_pair = str_replace(current_pair, "hello", cluster)) %>%
group_by(domain, current_pair) %>%
summarise(mean_response = mean(response),
num_responses = n())
plot_all_lexical = all_lexical%>%
left_join(plot_agg) %>%
filter(!is.na(mean_response)) %>%
mutate(Frequency_Value_scaled = avg_freq/10) %>%
rename(`semantic similarity` = Semantic_Similarity,
`phonological similarity` = Phonological_Similarity,
`word frequency` = Frequency_Value_scaled) %>%
pivot_longer(names_to = "cue", cols = c(`semantic similarity`, `phonological similarity`, `word frequency`))%>%
mutate(cue = as.factor(cue),
cue = fct_relevel(cue, "semantic similarity", "phonological similarity", "word frequency"))
plot_all_lexical %>%
ggplot(aes(x = value, y =mean_response, group = domain, color = domain )) +
geom_point(alpha = 0.1)+
geom_smooth(method = "lm")+
ylim(0,1)+
labs(title = "",
x = "mean lexical values",
y = "mean rating of word pairs") +
theme_minimal()+
facet_wrap(~cue)+
scale_color_gdocs()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.2)))
ratings_lexical_model_semantic = lmer(data = plot_all_lexical %>% filter(cue == "semantic similarity"),
mean_response ~ value*domain + (1 | Subject))
car::Anova(ratings_lexical_model_semantic)
rater_data <- trials_agg %>%
ungroup() %>%
mutate(norms_associative = ifelse(is.na(norms_associative), 0, norms_associative),
norms_categorical = ifelse(is.na(norms_categorical), 0, norms_categorical))%>%
filter(!is.na(simdrop))
colnames(rater_data)
View(rater_data)
# Get the list of predictor variables (columns) from the dataframe
rater_predictor_columns <- setdiff(names(rater_data), c("mean_response", "subject", "domain", "response_number",
"current_pair", "num_responses", "cluster"))
# Clean predictor column names in the dataframe
rater_cleaned_data <- rater_data %>%
rename_with(clean_column_names, .cols = rater_predictor_columns)
# Get the list of predictor variables (columns) from the dataframe
rater_predictor_columns <- setdiff(names(rater_cleaned_data), c("mean_response", "subject", "domain", "response_number",
"current_pair", "num_responses", "cluster"))
rater_model_results <- rater_cleaned_data %>%
group_by(domain) %>%
summarise(
model = map(setNames(predictor_columns, predictor_columns),
~ fit_model(df = cur_data(), column = .x, type = "lmer", dv = "mean_response",
var_cutoff = .015))
)
rater_model_results <- rater_cleaned_data %>%
group_by(domain) %>%
summarise(
model = map(setNames(rater_predictor_columns, rater_predictor_columns),
~ fit_model(df = cur_data(), column = .x, type = "lmer", dv = "mean_response",
var_cutoff = .015))
)
# Function to clean column names by replacing special characters with underscores
clean_column_names <- function(column_names) {
str_replace_all(column_names, "[^[:alnum:] ]", "_")
}
n_bootstrap = 1000
calculate_bootstrap_r_squared <- function(data, type, n_bootstrap, formula) {
# Define an empty vector to store R-squared values
r_squared_values <- numeric(n_bootstrap)
# Calculate R-squared for each bootstrap sample
for (i in 1:n_bootstrap) {
# Generate random indices with replacement
indices <- sample(nrow(data), replace = TRUE)
# Subset data using the random indices
sampled_data <- data[indices, ]
# Fit your model using the sampled data
if(type == "glmer"){
model <- eval(bquote(glmer(.(formula), data = .(substitute(sampled_data)), family = binomial)))
# Calculate R-squared and store it in the vector
r_squared_values[i] <- MuMIn::r.squaredGLMM(model)[4]
}
else{
model <- lmer(formula, data = sampled_data)
# Calculate R-squared and store it in the vector
r_squared_values[i] <- MuMIn::r.squaredGLMM(model)[2]
}
}
# Calculate confidence intervals of R-squared values
ci_r_squared <- quantile(r_squared_values, c(0.025, 0.975))
return(ci_r_squared)
}
# Define a function to fit the glmer model for each cleaned predictor column
fit_model <- function(df, column, type, dv, var_cutoff) {
# calculate variance of the column
var_col = var(df[column])
if (var_col > var_cutoff) {
if(type == "glmer"){
model_formula <- as.formula(paste(dv, " ~ ", column, "+ (1 | subject)"))
model <- glmer(model_formula, data = df, family = binomial)
estimate <- fixef(model)[column]
r_squared <- MuMIn::r.squaredGLMM(model)[4] # conditional delta R-squared
ci_r_squared <- calculate_bootstrap_r_squared(data = df, type, n_bootstrap = n_bootstrap, formula = model_formula)
}
else { #if(type == "lmer") {
model_formula <- as.formula(paste(dv, " ~ ", column, "+ (1 | subject)"))
model <- lmer(model_formula, data = df)
estimate <- fixef(model)[column]
r_squared <- MuMIn::r.squaredGLMM(model)[2] # conditional R-squared
ci_r_squared <- calculate_bootstrap_r_squared(data = df, type, n_bootstrap = n_bootstrap, formula = model_formula)
}
aic <- AIC(model)
bic <- BIC(model)
log_likelihood <- as.numeric(logLik(model))
n_obs <- nobs(model)
result <- tibble(
Predictor = column,
Fixed_Effect = estimate,
AIC = aic,
BIC = bic,
R_squared = r_squared,
Log_Likelihood = log_likelihood,
N_Observations = n_obs,
R_squared_CI_lower = ci_r_squared[1],  # Lower bound of CI
R_squared_CI_upper = ci_r_squared[2]   # Upper bound of CI
)
return(result)
}
else{
return(NULL)
}
}
rater_model_results <- rater_cleaned_data %>%
group_by(domain) %>%
summarise(
model = map(setNames(rater_predictor_columns, rater_predictor_columns),
~ fit_model(df = cur_data(), column = .x, type = "lmer", dv = "mean_response",
var_cutoff = .015))
)
x= readxl::read_excel("20231214_v2_gameData.xlsx")
warnings()
rater_model_results_unnested = rater_model_results %>% unnest()
best_rating_models = rater_model_results_unnested %>%
mutate(Predictor = ifelse(Predictor == "norms_associative", "associative",
ifelse(Predictor == "norms_categorical", "categorical", Predictor))) %>%
separate(Predictor, sep = "_", into = c("Predictor", "param1", "p1_0", "p1_val", "param2", "p2_0", "p2_val", "param3", "p3_0", "p3_val")) %>%
filter(Predictor != "exp")%>%
group_by(domain, Predictor) %>%
slice_max(R_squared) %>%
arrange(domain, desc(R_squared))
View(best_rating_models)
View(LEA_cleaned_data)
View(trials_agg)
View(LEA_cleaned_data)
exploratory_data = LEA_cleaned_data %>%
select(domain, subject, cluster, participant_designated_switch, response_number ) %>%
left_join((trials_agg %>% select(domain, subject, cluster, mean_response, response_number )))
exploratory_data = LEA_cleaned_data %>%
mutate(subject = as.character(subject)) %>%
select(domain, subject, cluster, participant_designated_switch, response_number ) %>%
left_join((trials_agg %>% select(domain, subject, cluster, mean_response, response_number )))
View(exploratory_data)
exploratory_data = LEA_cleaned_data %>%
mutate(subject = as.character(subject)) %>%
select(domain, subject, cluster, participant_designated_switch, response_number ) %>%
left_join((trials_agg %>% select(domain, subject, cluster, mean_response, response_number ))) %>%
filter(!is.na(mean_response))
exploratory_lm = glmer(data = exploratory_data, participant_designated_switch ~ mean_response + (1|subject),
family = binomial)
summary(exploratory_lm)
MuMIn::r.squaredGLMM(exploratory_lm)
exploratory_lm = glmer(data = exploratory_data, participant_designated_switch ~ mean_response + (mean_response|subject),
family = binomial)
summary(exploratory_lm)
MuMIn::r.squaredGLMM(exploratory_lm)
MuMIn::r.squaredGLMM(exploratory_lm)[4]
MuMIn::r.squaredGLMM(exploratory_lm)
## we want to see how "idiosyncratic" a response is based on how many people rated it as a cluster or switch
LEA_data_idio = rbind(LEA_animals, LEA_foods, LEA_occupations)
idio_data = nonfirst_trials %>% filter(subject > 5000) %>%
mutate(current_pair = str_replace(current_pair, "hello", cluster),
subject = as.character(subject)) %>%
group_by(domain, subject, response_number, current_pair, response) %>%
summarize(N = n())%>%
pivot_wider(names_from = response, values_from = N) %>%
rename(cluster_N = "0", switch_N = "1") %>% mutate(across(c(cluster_N, switch_N), ~coalesce(., 0))) %>%
left_join(LEA_data_idio %>% mutate(subject = as.character(subject)))%>%
mutate(idiosyncratic = ifelse(participant_designated_switch == 0, (switch_N / (cluster_N + switch_N)),
(cluster_N / (cluster_N + switch_N)))) %>%
filter(!is.na(idiosyncratic))
## total N per list
total_n = idio_data %>% mutate(N = cluster_N + switch_N) %>% select(subject, N) %>% ungroup() %>% select(subject, N)%>% unique()
mean(total_n$N)
sd(total_n$N)
idio_lexical = idio_data %>%
#mutate(current_pair = str_replace(current_pair, ", ", "-"))%>%
rename(Subject = "subject") %>% mutate(Subject = as.character(Subject)) %>%
left_join(all_lexical %>% mutate(Subject = as.character(Subject))) %>%
mutate(Frequency_Value_scaled = avg_freq/10) %>%
rename(`semantic similarity` = Semantic_Similarity,
`phonological similarity` = Phonological_Similarity,
`word frequency` = Frequency_Value_scaled) %>%
pivot_longer(names_to = "cue", cols = c(`semantic similarity`, `phonological similarity`, `word frequency`))%>%
mutate(cue = as.factor(cue),
cue = fct_relevel(cue, "semantic similarity", "phonological similarity", "word frequency"))
idio_lexical_semantic = lmer(data = idio_lexical %>% filter(cue == "semantic similarity"),
idiosyncratic ~ value*domain + (domain|Subject))
summary(idio_lexical_semantic)
car::Anova(idio_lexical_semantic)
idio_lexical_phonological = lmer(data = idio_lexical %>% filter(cue == "phonological similarity"),
idiosyncratic ~ value*domain + (domain|Subject))
summary(idio_lexical_phonological)
car::Anova(idio_lexical_phonological)
idio_lexical_frequency = lmer(data = idio_lexical %>% filter(cue == "word frequency"),
idiosyncratic ~ value*domain + (domain|Subject))
summary(idio_lexical_frequency)
car::Anova(idio_lexical_frequency)
idio_lexical %>%
ggplot(aes(x = value, y =idiosyncratic, group = domain, color = domain )) +
geom_point(alpha = 0.1)+
geom_smooth(method = "lm")+
ylim(0,1)+
labs(title = "",
x = "lexical values",
y = "idiosyncratic score") +
theme_minimal()+
scale_color_gdocs()+
facet_wrap(~cue)+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.2)))
LEA_idio = idio_data %>% group_by(domain, subject) %>%
summarise(avg_idio = mean(idiosyncratic),
items = n()) %>%
mutate(domain = as.factor(domain))
LEA_idio %>%
ggplot(aes(x=avg_idio, group = domain, fill = domain)) +
geom_density(alpha = 0.4)+
labs(title = "Distribution of Mean Idiosyncratic Scores for Different Domains",
x = "individual idiosyncratic score",
y = "density") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.2)))
LEA_idio %>%
ggplot(aes(x=avg_idio, group = domain, fill = domain)) +
geom_density(alpha = 0.4)+
labs(title = "Distribution of Individual-Level Idiosyncratic Scores for Different Domains",
x = "individual idiosyncratic score",
y = "density") +
theme_minimal()+
scale_fill_excel()+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1.5)),
axis.title = element_text(size =rel(2)),
plot.title = element_text(hjust = .5, size = rel(1.2)))
LEA_idio = idio_data %>% group_by(domain, subject) %>%
summarise(avg_idio = mean(idiosyncratic),
items = n()) %>%
mutate(domain = as.factor(domain))
View(LEA_idio)
domain_idio_agg = LEA_idio %>%
select(subject, domain, avg_idio) %>%
pivot_wider(names_from = domain, values_from = avg_idio)
View(domain_idio_agg)
# Step 2: Train your original models and get Rsquared
model_animals_foods <- summary(lm(animals ~ foods, data = domain_idio_agg))$r.squared
model_animals_occupations <- summary(lm(animals ~ occupations, data = domain_idio_agg))$r.squared
model_foods_animals <- summary(lm(foods ~ animals, data = domain_idio_agg))$r.squared
model_foods_occupations <- summary(lm(foods ~ occupations, data = domain_idio_agg))$r.squared
model_occupations_animals <- summary(lm(occupations ~ animals, data = domain_idio_agg))$r.squared
model_occupations_foods <- summary(lm(occupations ~ foods, data = domain_idio_agg))$r.squared
# Set seed for reproducibility
set.seed(123)
# Assuming 'domains' is a vector of domain names
domains <- c("animals", "foods", "occupations")
# Initialize a matrix to store R-squared values
num_permutations <- 1000
r_squared_values <- matrix(NA, nrow = num_permutations * length(domains), ncol = 3)
row_counter <- 1
for (constant_column in domains) {
shuffled_columns = domains[domains != constant_column]
for (i in 1:num_permutations) {
shuffled_column_1 = sample(domain_idio_agg %>% pull(shuffled_columns[1]))
shuffled_column_2 = sample(domain_idio_agg %>% pull(shuffled_columns[2]))
df_shuffled = domain_idio_agg %>% select(subject, constant_column)%>%
cbind(shuffled_column_1, shuffled_column_2)
formula1 = paste(constant_column, "~ shuffled_column_1")
formula2 = paste(constant_column, "~ shuffled_column_2")
model_1 <- lm(formula1, data = df_shuffled)
model_2 <- lm(formula2,  data = df_shuffled)
r_squared_values[row_counter, 1] <- constant_column
r_squared_values[row_counter, 2] <- summary(model_1)$r.squared
r_squared_values[row_counter, 3] <- summary(model_2)$r.squared
row_counter <- row_counter + 1
}
}
r_squared_values = as.data.frame(r_squared_values)
animals_data = r_squared_values %>% filter(V1 == "animals") %>%
pivot_longer(names_to = "model", cols = V2:V3) %>%
mutate(datatype = "permuted")%>%
rbind(data.frame(V1 = "animals", model = "V2", value= model_animals_foods, datatype = "original"),
data.frame(V1 = "animals", model = "V3", value= model_animals_occupations, datatype = "original") )%>%
mutate(value = as.numeric(value), model = as.factor(model), datatype = as.factor(datatype))%>%
mutate(model = ifelse(model == "V2", "animals ~ foods", "animals ~ occupations"))
foods_data = r_squared_values %>% filter(V1 == "foods") %>%
pivot_longer(names_to = "model", cols = V2:V3) %>%
mutate(datatype = "permuted")%>%
rbind(data.frame(V1 = "foods", model = "V2", value= model_foods_animals, datatype = "original"),
data.frame(V1 = "foods", model = "V3", value= model_foods_occupations, datatype = "original") )%>%
mutate(value = as.numeric(value), model = as.factor(model), datatype = as.factor(datatype))%>%
mutate(model = ifelse(model == "V2", "foods ~ animals", "foods ~ occupations"))
occupations_data = r_squared_values %>% filter(V1 == "occupations") %>%
pivot_longer(names_to = "model", cols = V2:V3) %>%
mutate(datatype = "permuted")%>%
rbind(data.frame(V1 = "occupations", model = "V2", value= model_occupations_animals, datatype = "original"),
data.frame(V1 = "occupations", model = "V3", value= model_occupations_foods, datatype = "original") )%>%
mutate(value = as.numeric(value), model = as.factor(model), datatype = as.factor(datatype))%>%
mutate(model = ifelse(model == "V2", "occupations ~ animals", "occupations ~ foods"))
combined_data= rbind(animals_data, foods_data, occupations_data)  %>%
rename(domain = "V1")
ggplot(combined_data, aes(x = value, fill = model)) +
geom_histogram(binwidth = 0.01, position = "dodge") +
facet_wrap(~domain, ncol = 1, scales = "free_y") +
geom_vline(data = combined_data %>% filter(datatype == "original"),
aes(xintercept = value, color = model), linetype = "dashed") +
labs(x = "R-squared", y = "Frequency") +
theme_minimal()
# Calculate the mean of shuffled R-squared values
permutation_test <- combined_data %>%
group_by(domain, model) %>%
summarise(p_value = {
obs_value <- value[datatype == "original"]
permuted_values <- value[datatype == "permuted"]
formatted_p_value <- sprintf("%.6e", sum(permuted_values >= obs_value) / length(permuted_values))
as.numeric(formatted_p_value)  # Convert back to numeric
})
View(permutation_test)
## mean idio score
LEA_idio = idio_data %>% group_by(domain, subject) %>%
summarise(avg_idio = mean(idiosyncratic),
items = n()) %>%
mutate(domain = as.factor(domain))
## do people who produce more idiosyncratic responses produce more items?: NO
items_lm = lm(data = LEA_idio, items ~ avg_idio*domain)
summary(items_lm)
car::Anova(items_lm)
LEA_idio %>%
ggplot(aes(x= items, y = avg_idio, group = domain, color = domain)) +
geom_point() +
geom_smooth(method = "lm")+
theme_minimal()+
scale_color_gdocs()+
labs(x = "number of items", y = "participant idiosyncratic score")+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1)),
axis.title = element_text(size =rel(1.5)),
plot.title = element_text(hjust = .5, size = rel(1.2)))
cluster_info = rbind((read_csv("forager_test/output/foods_forager/individual_descriptive_stats.csv") %>%
mutate(domain = "foods") %>%
filter(Switch_Method %in% c("multimodaldelta_alpha=0.7000000000000001_rise=1.0_fall=0.5"))),
(read_csv("forager_test/output/animals_forager/individual_descriptive_stats.csv") %>%
mutate(domain = "animals") %>%
filter(Switch_Method %in% c("multimodaldelta_alpha=0.8_rise=1.0_fall=0.25"))),
(read_csv("forager_test/output/occupations_forager/individual_descriptive_stats.csv") %>%
mutate(domain = "occupations") %>%
filter(Switch_Method %in% c("multimodaldelta_alpha=0.9_rise=0.75_fall=0.0")))) %>%
rename(subject = "Subject") %>%
mutate(subject = as.character(subject)) %>%
mutate(Switch_Method = ifelse(Switch_Method == "norms_associative", "associative",
"multimodal_delta")) %>%
dplyr::select(subject, Switch_Method, Number_of_Switches, Cluster_Size_mean, domain)
LEA_idio_clusters = LEA_idio %>% left_join(cluster_info) %>% mutate(n_clusters = Number_of_Switches + 1)
idio_cluster_model = lm(data = LEA_idio_clusters,
avg_idio ~ Cluster_Size_mean*domain)
summary(idio_cluster_model)
car::Anova(idio_cluster_model)
idio_switch_model = lm(data =LEA_idio_clusters ,
avg_idio ~ n_clusters*domain)
summary(idio_switch_model)
car::Anova(idio_switch_model)
LEA_idio_clusters %>%
ggplot(aes(x= n_clusters, y = avg_idio, group = domain, color = domain)) +
geom_point() +
geom_smooth(method = "lm")+
theme_minimal()+
scale_color_gdocs()+
labs(x = "number of clusters", y = "participant idiosyncratic score")+
theme(plot.background = element_rect(
color = "white"),
strip.text.x = element_text(size =rel(2)),
axis.text = element_text(size =rel(1)),
axis.title = element_text(size =rel(1.5)),
plot.title = element_text(hjust = .5, size = rel(1.2)))
strategies = data %>%
filter(ID %in% trials$ID) %>%
filter(type_of_trial == "demo"  & str_detect(response, '^\\{"Q0":"')) %>%
filter(row_number() %% 2 != 0)%>%
mutate(response = str_extract(response, '(?<=Q0":").*?(?=")')) %>%
select(ID,response)
