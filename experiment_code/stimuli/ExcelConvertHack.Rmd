---
title: "Hack Excel convert to Js File"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r}
library(jsonlite)
library(tidyverse)
library(dplyr)
```

# Combining all data

```{r}
path_trial = paste(getwd(), "/lists/", sep = "")
final_fluency <- list.files(path =path_trial, pattern = "*.xlsx", full.names = TRUE) %>% 
  lapply(readxl::read_excel) %>% 
  bind_rows %>%
  select(subject, domain,spellcheck, ctime)%>%
  rename(word = spellcheck) %>%
  filter(!is.na(subject))%>%
  filter(subject != 71)


## general descriptives: num items/domain

final_fluency %>% group_by(domain, subject) %>%
  count() %>%
  group_by(domain) %>% summarize(mean= mean(n))

## taking a random sample for testing
set.seed(100)
test = sample(unique(final_fluency %>% pull(subject)) , 30)

final_data = final_fluency %>% filter(subject %in% test) %>%
  group_by(subject) %>%
  mutate(SIDNO = cur_group_id()) %>%
  filter(domain %in% c("ANIMALS", "FOODS", "OCCUPATIONS"))

write.csv(final_data, "final_lists.csv", row.names = FALSE)
```

# adding info

```{r}
lists = read_csv("final_60.csv")

lists = lists %>%
  mutate(domain = tolower(domain)) %>%
  group_by(subject, domain) %>%
  mutate(response_number = row_number(),
         IRT_prev = lag(response_onset_time),
         IRT_prev= ifelse(is.na(IRT_prev), 0, IRT_prev),
         IRT = response_onset_time-IRT_prev,
         prev_word = lag(participant_response),
         repetition = ifelse(participant_response == prev_word, 1,0),
         repetition = ifelse(is.na(repetition), 0, repetition)) %>%
  filter(repetition != 1) %>%
  select(-c(prev_word, repetition, IRT_prev))

unique_HJT = unique(lists %>% filter(dataset == "HJT") %>% pull(subject))
list1_HJT = sample(unique_HJT, 15)

unique_LEA = unique(lists %>% filter(dataset == "LEA") %>% pull(subject))
list1_LEA = sample(unique_LEA, 15)


list1 = lists %>% filter(subject %in% c(list1_HJT, list1_LEA)) %>% mutate(list_number = 1)
list2 = lists %>% filter(!subject %in% c(list1_HJT, list1_LEA))%>% mutate(list_number = 2)

write.csv(list1, "list1.csv", row.names = FALSE)
write.csv(list2, "list2.csv", row.names = FALSE)
```

# json conversion
```{r}
final_data = read_csv("final_lists.csv")
new = final_data %>% select(subject, domain, participant_response)%>% group_by(subject,domain) %>%
  summarise(across(everything(), ~ paste(participant_response, collapse = ", "))) %>% 
  ungroup() %>%
  mutate(participant_response = strsplit(participant_response, ", ")) %>% 
  left_join(final_data %>% select(-participant_response))

list = new %>% filter(SIDNO %in% 1:10) %>% arrange(domain)
toJSON(new)
```

# alternative code

```{r}
#Split datafile into datafiles for each subject
forlist<-unique(data$Subject)
for(i in 1:length(forlist)){
     a<-filter(data, Subject==forlist[i])
     assign(paste0("data", i), a)
}

#Convert each subject's datafile into js format
for(z in 1:length(forlist)) {
  c<-get(paste0("data", z))
  b<-toJSON(c, dataframe="columns", pretty=TRUE)
  assign(paste0("json",z),b)
}

#Print json files for easy copying
for(x in 1:length(forlist)) {
  d<-get(paste0("json", x))
  print(d)
}
```

